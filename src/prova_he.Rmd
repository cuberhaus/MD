# Go to the folder where you have stored the MD repo before running the script
#install.packages("rmarkdown")
#library("rmarkdown")


```{r}
# ENVIROMENT 

#dir <- getwd()     # descomenta esto si lo quieres usar en tu ordenador
dir <- "/home/he/Desktop/MD/" 
col_names <- variable_names <- c("age", "class of worker", "detailed industry recode", 
                    "detailed occupation recode", "education", "wage per hour", 
                    "enroll in edu inst last wk", "marital stat", "major industry code", 
                    "major occupation code", "race", "hispanic origin", "sex", 
                    "member of a labor union", "reason for unemployment", 
                    "full or part time employment stat", "capital gains", "capital losses", 
                    "dividends from stocks", "tax filer stat", "region of previous residence", 
                    "state of previous residence", "detailed household and family stat", 
                    "detailed household summary in household", "instance weight", 
                    "migration code-change in msa", "migration code-change in reg", 
                    "migration code-move within reg", "live in this house 1 year ago", 
                    "migration prev res in sunbelt", "num persons worked for employer", 
                    "family members under 18", "country of birth father", 
                    "country of birth mother", "country of birth self", "citizenship", 
                    "own business or self employed", "fill inc questionnaire for veteran's admin", 
                    "veterans benefits", "weeks worked in year", "year")


db <- read.csv(paste0(dir,"/data/raw_data/census-income.data"),header=F, sep=",", strip.white = TRUE) # take out trailing whitespaces

# Assign the column names to the data frame
colnames(db) <- col_names

```
#mean(is.na(db)) * 100
#num_question_marks <- sum(db == "?", na.rm = TRUE)
#total_cells = ncol(db) * nrow(db)


```{r}

# transformacion missing values to NA
db[db == "Not in universe"] <- NA
db[db == "Not in universe or children"] <- NA
db[db == "?"] <- NA
db[db == "Not in universe under 1 year old"] <- NA

```


```{r}
#calculo % de missing data para cada columna
colMeans(is.na(db)) * 100

# Eliminar columnas 
db$year <- NULL      # columna que no aporta ninguna informacion
#db <- db[, colMeans(is.na(db)) < 0.9]  # Eliminar todas %missing data > 90%
db$`enroll in edu inst last wk` <- NULL
db$`member of a labor union` <- NULL
db$`reason for unemployment` <- NULL
db$`region of previous residence` <- NULL
db$`state of previous residence` <- NULL
db$`migration prev res in sunbelt` <- NULL
db$`fill inc questionnaire for veteran's admin` <- NULL
```

```{r}
# Imputacion: me da ERRORES, chatGPT no se aclara

# sudo apt-get install libcurl4-openssl-dev
# sudo apt-get install libxml2-dev

# Convert all columns to factors for imputation
#data[] <- lapply(db, factor)

library(VIM)

# Identify missing values
missing_values <- db == "?" | db == "Not in universe" | db == "Not in universe or children" | db == "Not in universe under 1 year old"

# Impute missing values using kNN
db_imputed <- kNN(db, k = 5, numFun = "WeightedMean", use.all.vars = TRUE)

# Check if there are still missing values
any(is.na(db_imputed))

```


```{r}





```


# grepl returns whether that value is found or not
col_missing <- colSums(sapply(db, function(x) grepl("\\?", x)))
col_missing

col_percents <- colSums(sapply(db, function(x) grepl("\\?", x)))/ nrow(db) * 100
col_percents

average_missing <- (sum(col_percents, na.rm = TRUE) / length(col_percents)) 
average_missing

summary(db)
# Get all the unique values for each column
unique_values <- lapply(df, unique)
unique_values <- lapply(db, function(x) length(unique(x)))

db <- db[, -26]
db <- db[, -27]
db <- db[, -28]
db <- db[, -30]

install.packages("caret")
library(caret)

#define one-hot encoding function
dummy <- dummyVars(" ~ .", data=db)

#perform one-hot encoding on data frame
db_hot <- data.frame(predict(dummy, newdata=db))
# Need to use one-hot encoding first

# Load the dplyr package
#install.packages("dplyr")
library(dplyr)

# Write the data frame to a CSV file
write.table(data, file = "data/processed_data/one_hot_db.csv", sep = ",", row.names = FALSE)

# Select only the categorical variables
numerical_data <- select_if(db, is.numeric)
categorical_data <- select_if(db, is.character)

# Perform PCA on the data
pca <- prcomp(numerical_data, scale. = TRUE)

# View the results
summary(pca)

#write.table(data, file = "data/processed_data/one_hot_db.csv", sep = ",", row.names = FALSE)

install.packages("corrplot")

# Load the corrplot package
library(corrplot)
# View the correlation matrix only of the numerical values
cor_mat<- cor(numerical_data)
# Set the upper triangle elements to NA
cor_mat[upper.tri(cor_mat)] <- NA

corrplot(cor_mat, method="circle")
colnames(db) <- c("age", "class of worker", "detailed industry recode", "detailed occupation recode", "education", "wage per hour", "enroll in edu inst last wk", "marital stat", "major industry code", "major occupation code", "race", "hispanic origin", "sex", "member of a labor union", "reason for unemployment", "full or part time employment stat", "capital gains", "capital losses", "dividends from stocks", "tax filer stat", "region of previous residence", "state of previous residence", "detailed household and family stat", "detailed household summary in household", "instance weight", "migration code-change in msa", "migration code-change in reg", "migration code-move within reg", "live in this house 1 year ago", "migration prev res in sunbelt", "num persons worked for employer", "family members under 18", "country of birth father", "country of birth mother", "country of birth self", "citizenship", "own business or self employed", "fill inc questionnaire for veteran's admin", "veterans benefits", "weeks worked in year", "year", "income")
